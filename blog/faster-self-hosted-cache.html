<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><meta name="theme-color" content="#000000"/><meta name="author" content="OpenFaaS Ltd"/><meta name="twitter:card" content="summary_large_image"/><title>Fixing the cache latency for self-hosted GitHub Actions</title><meta name="description" content="The cache for GitHub Actions can speed up CI/CD pipelines. But what about when it slows you down?"/><meta property="twitter:title" content="Fixing the cache latency for self-hosted GitHub Actions"/><meta property="twitter:description" content="The cache for GitHub Actions can speed up CI/CD pipelines. But what about when it slows you down?"/><meta property="og:title" content="Fixing the cache latency for self-hosted GitHub Actions"/><meta property="og:description" content="The cache for GitHub Actions can speed up CI/CD pipelines. But what about when it slows you down?"/><meta name="twitter:image:src" content="https://actuated.dev/images/2023-05-faster-cache/background.png"/><meta property="og:image" content="https://actuated.dev/images/2023-05-faster-cache/background.png"/><meta name="next-head-count" content="13"/><meta charSet="utf-8"/><link rel="icon" type="image/png" href="/images/actuated.png"/><link rel="stylesheet" href="https://rsms.me/inter/inter.css"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/github-dark.min.css"/><link rel="manifest" href="/manifest.json"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-M5YNDNX7VT"></script><script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());

          gtag('config', 'G-M5YNDNX7VT');
          </script><link rel="apple-touch-icon" href="/images/actuated.png"/><link rel="preload" href="/_next/static/css/af91c5ff992635f2.css" as="style"/><link rel="stylesheet" href="/_next/static/css/af91c5ff992635f2.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-8fa1640cc84ba8fe.js" defer=""></script><script src="/_next/static/chunks/framework-114634acb84f8baa.js" defer=""></script><script src="/_next/static/chunks/main-34e2100d07ae5757.js" defer=""></script><script src="/_next/static/chunks/pages/_app-c5247403fc8e2604.js" defer=""></script><script src="/_next/static/chunks/552-542f150c917a7625.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-109b0d2eddac75b5.js" defer=""></script><script src="/_next/static/n3VvHl02riewG3IqG5uON/_buildManifest.js" defer=""></script><script src="/_next/static/n3VvHl02riewG3IqG5uON/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="bg-white"><header><div class="relative bg-white" data-headlessui-state=""><div class="mx-auto flex max-w-7xl items-center justify-between px-4 py-6 sm:px-6 md:justify-start md:space-x-10 lg:px-8"><div class="flex justify-start lg:w-0 lg:flex-1"><a href="/"><span class="sr-only">Actuated</span><img class="h-8 w-auto sm:h-10" src="/images/actuated.png" alt="Actuated logo"/></a></div><div class="-my-2 -mr-2 md:hidden"><button class="inline-flex items-center justify-center rounded-md bg-white p-2 text-gray-400 hover:bg-gray-100 hover:text-gray-500 focus:outline-none focus:ring-2 focus:ring-inset focus:ring-indigo-500" type="button" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Open menu</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" class="h-6 w-6"><path stroke-linecap="round" stroke-linejoin="round" d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5"></path></svg></button></div><nav class="hidden space-x-10 md:flex"><div class="relative" data-headlessui-state=""><button class="text-gray-500 group inline-flex items-center rounded-md bg-white text-base font-medium hover:text-gray-900 focus:outline-none focus:ring-2 focus:ring-indigo-500 focus:ring-offset-2" type="button" aria-expanded="false" data-headlessui-state=""><span>Solutions</span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" aria-hidden="true" class="text-gray-400 ml-2 h-5 w-5 group-hover:text-gray-500"><path fill-rule="evenodd" d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z" clip-rule="evenodd"></path></svg></button></div><a class="text-base font-medium text-gray-500 hover:text-gray-900" href="/blog">Blog</a><a class="text-base font-medium text-gray-500 hover:text-gray-900" href="https://actuated.dev/blog/blazing-fast-ci-with-microvms">Announcement</a><a class="text-base font-medium text-gray-500 hover:text-gray-900" href="https://docs.actuated.dev/">Docs</a></nav><div class="hidden items-center justify-end md:flex md:flex-1 lg:w-0"><a href="https://dashboard.actuated.dev" class="whitespace-nowrap text-base font-medium text-gray-500 hover:text-gray-900">Sign in</a><a href="https://docs.actuated.dev/register/" class="ml-8 inline-flex items-center justify-center whitespace-nowrap rounded-md border border-transparent bg-indigo-600 px-4 py-2 text-base font-medium text-white shadow-sm hover:bg-indigo-700">Sign-up</a></div></div></div></header><main><div class="container mx-auto max-w-4xl bg-white mt-4 px-4 sm:px-6"><h1 id="post_title" class="text-3xl mb-3 leading-8 font-extrabold tracking-tight text-gray-900 sm:text-4xl sm:leading-10 text-center">Fixing the cache latency for self-hosted GitHub Actions</h1></div><div class="container mx-auto px-4 sm:px-6 lg:px-8 max-w-4xl"><div class="border-b border-gray-200 py-4 flex items-center text-gray-500 mx-auto"><div><img class="h-10 w-10 rounded-full" src="/images/alex.jpg" alt=""/></div><div class="ml-3"><p id="post_author" class="text-sm leading-5 font-medium text-gray-900"></p><div class="flex text-sm leading-5 text-gray-500"><time dateTime="2023-05-24" id="post_date">May 24, 2023</time><span class="mx-1"></span></div></div></div><div class="mt-6 prose sm:prose-lg max-w-none"><p id="post_description" class="mb-4">The cache for GitHub Actions can speed up CI/CD pipelines. But what about when it slows you down?</p></div><div id="post_content" class="mt-6 prose sm:prose-lg max-w-none"><p>In some of our builds for actuated we cache things like the Linux Kernel, so we don't needlessly rebuild it when we update packages in our base images. It can shave minutes off every build meaning our servers can be used more efficiently. Most customers we've seen so far only make light to modest use of GitHub's hosted cache, so haven't noticed much of a latency problem.</p>
<p>But you don't have to spend too long on the <a href="https://github.com/actions/cache/issues?q=is%3Aissue+cache+slow+">issuer tracker for GitHub Actions</a> to find people complaining about the cache being slow or locking up completely for self-hosted runners.</p>
<p>Go, Rust, Python and other languages don't tend to make heavy use of caches, and Docker has some of its own mechanisms like building cached steps into published images aka <em><a href="https://docs.docker.com/build/cache/backends/inline/">inline caching</a></em>. But for the Node.js ecosystem, the <code>node_modules</code> folder and yarn cache can become huge and take a long time to download. That's one place where you may start to see tension between the speed of self-hosted runners and the latency of the cache. If your repository is a monorepo or has lots of large artifacts, you may get a speed boost by caching that too.</p>
<p>So why is GitHub's cache so fast for hosted runners, and (sometimes) so slow self-hosted runners?</p>
<p>Simply put - GitHub runs VMs and the accompanying cache on the same network, so they can talk over a high speed backbone connection. But when you run a self-hosted runner, then any download or upload operations are taking place over the public Internet.</p>
<p>Something else that can slow builds down is having to download large base images from the Docker Hub. We've already <a href="https://docs.actuated.dev/tasks/registry-mirror/">covered how to solve that for actuated in the docs</a>.</p>
<h2>Speeding up in the real world</h2>
<p>We recently worked with Roderik, the CTO of <a href="https://settlemint.com">SettleMint</a> to migrate their CI from a self-hosted Kubernetes solution Actions Runtime Controller (ARC) to actuated. He told me that they originally moved from GitHub's hosted runners to ARC to save money, increase speed and to lower the latency of their builds. Unfortunately, running container builds within Kubernetes provided very poor isolation, and side effects were being left over between builds, even with a pool of ephemeral containers. They also wanted to reduce the amount of effort required to maintain a Kubernetes cluster and control-plane for CI.</p>
<p>Roderik explained that he'd been able to get times down by using <a href="https://pnpm.io">pnpm</a> instead of yarn, and said every Node project should try it out to see the speed increases. He believes the main improvement is due to efficient downloading and caching. pnpm is a drop-in replacement for npm and yarn, and is compatible with both.</p>
<blockquote>
<p>In some cases, we found that downloading dependencies from the Internet was faster than using GitHub's remote cache. The speed for a hosted runner was often over 100MBs/sec, but for a self-hosted runner it was closer to 20MBs/sec.</p>
</blockquote>
<p>That's when we started to look into how we could run a cache directly on the same network as our self-hosted runners, or even on the machine that was scheduling the Firecracker VMs.</p>
<blockquote>
<p>"With the local cache that Alex helped us set up, the cache is almost instantaneous. It doesn't even have time to show a progress bar."</p>
</blockquote>
<p>Long story short, SettleMint have successfully migrated their CI for x86 and Arm to actuated for the whole developer team:</p>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Super happy with my new self hosted GHA runners powered by <a href="https://twitter.com/selfactuated?ref_src=twsrc%5Etfw">@selfactuated</a>, native speeds on both AMD and ARM bare metal monster machines. Our CI now goes brrrrâ€¦ <a href="https://t.co/quZ4qfcLmu">pic.twitter.com/quZ4qfcLmu</a></p>&mdash; roderik.eth (@r0derik) <a href="https://twitter.com/r0derik/status/1661109934346346510?ref_src=twsrc%5Etfw">May 23, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>This post is about speed improvements for caching, but if you're finding that QEMU is too slow to build your Arm containers on hosted runners, you may benefit from switching to actuated with bare-metal Arm servers.</p>
<p>See also:</p>
<ul>
<li><a href="https://actuated.dev/blog/how-to-run-multi-arch-builds-natively">How to split up multi-arch Docker builds to run natively</a></li>
<li><a href="https://actuated.dev/blog/native-arm64-for-github-actions">How to make GitHub Actions 22x faster with bare-metal Arm</a></li>
</ul>
<h2>Set up a self-hosted cache for GitHub Actions</h2>
<p>In order to set up a self-hosted cache for GitHub Actions, we switched out the official <a href="https://github.com/actions/cache">actions/cache@v3</a> action for <a href="https://github.com/tespkg/actions-cache">tespkg/actions-cache@v1</a> created by Target Energy Solutions, a UK-based company, which can target S3 instead of the proprietary GitHub cache.</p>
<p>We then had to chose between Seaweedfs and Minio for the self-hosted S3 server. Of course, there's also nothing stopping you from actually using AWS S3, or Google Cloud Storage, or another hosted service.</p>
<p>Then, the question was - should we run the S3 service directly on the server that was running Firecracker VMs, for ultimate near-loopback speed, or on a machine provisioned in the same region, just like GitHub does with Azure?</p>
<p>Either would be a fine option. If you decide to host a public S3 cache, make sure that authentication and TLS are both enabled. You may also want to set up an IP whitelist just to deter any bots that may scan for public endpoints.</p>
<h3>Set up Seaweedfs</h3>
<p>The <a href="https://github.com/seaweedfs/seaweedfs">Seaweedfs</a> README describes the project as:</p>
<blockquote>
<p>"a fast distributed storage system for blobs, objects, files, and data lake, for billions of files! Blob store has O(1) disk seek, cloud tiering. Filer supports Cloud Drive, cross-DC active-active replication, Kubernetes, POSIX FUSE mount, S3 API, S3 Gateway, Hadoop, WebDAV, encryption, Erasure Coding."</p>
</blockquote>
<p>We liked it so much that we'd already added it to the arkade marketplace, arkade is a faster, developer-focused alternative to brew.</p>
<pre><code class="hljs language-bash">arkade get seaweedfs
sudo <span class="hljs-built_in">mv</span> ~/.arkade/bin/seaweedfs /usr/local/bin
</code></pre>
<p>Define a secret key and access key to be used from the CI jobs in the <code>/etc/seaweedfs/s3.conf</code> file:</p>
<pre><code>{
  "identities": [
    {
      "name": "actuated",
      "credentials": [
        {
          "accessKey": "s3cr3t",
          "secretKey": "s3cr3t"
        }
      ],
      "actions": [
        "Admin",
        "Read",
        "List",
        "Tagging",
        "Write"
      ]
    }
  ]
}
</code></pre>
<p>Create <code>seaweedfs.service</code>:</p>
<pre><code>[Unit]
Description=SeaweedFS
After=network.target

[Service]
User=root
ExecStart=/usr/local/bin/seaweedfs server -ip=192.168.128.1 -volume.max=0 -volume.fileSizeLimitMB=2048 -dir=/home/runner-cache -s3 -s3.config=/etc/seaweedfs/s3.conf
Restart=on-failure

[Install]
WantedBy=multi-user.target
</code></pre>
<p>We have set <code>-volume.max=0 -volume.fileSizeLimitMB=2048</code> to minimize the amount of space used and to allow large zip files of up to 2GB, but you can change this to suit your needs. See <code>seaweedfs server --help</code> for more options.</p>
<p>Install it and check that it started:</p>
<pre><code>sudo cp ./seaweedfs.service /etc/systemd/system/seaweedfs.service
sudo systemctl enable seaweedfs

sudo journalctl -u seaweedfs -f
</code></pre>
<h2>Try it out</h2>
<p>You'll need to decide what you want to cache and whether you want to use a hosted, or self-hosted S3 service - either directly on the actuated server or on a separate machine in the same region.</p>
<p>Roderik explained that the pnpm cache was important for node_modules, but that actually caching the git checkout saved a lot of time too. So he added both into his builds.</p>
<p>Here's an example:</p>
<pre><code class="hljs language-yaml">    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">"Set current date as env variable"</span>
      <span class="hljs-attr">shell:</span> <span class="hljs-string">bash</span>
      <span class="hljs-attr">run:</span> <span class="hljs-string">|
        echo "CHECKOUT_DATE=$(date +'%V-%Y')" >> $GITHUB_ENV
</span>      <span class="hljs-attr">id:</span> <span class="hljs-string">date</span>
    <span class="hljs-bullet">-</span> <span class="hljs-attr">uses:</span> <span class="hljs-string">tespkg/actions-cache@v1</span>
      <span class="hljs-attr">with:</span>
        <span class="hljs-attr">endpoint:</span> <span class="hljs-string">"192.168.128.1"</span>
        <span class="hljs-attr">port:</span> <span class="hljs-number">8333</span>
        <span class="hljs-attr">insecure:</span> <span class="hljs-literal">true</span>
        <span class="hljs-attr">accessKey:</span> <span class="hljs-string">"s3cr3t"</span>
        <span class="hljs-attr">secretKey:</span> <span class="hljs-string">"s3cr3t"</span>
        <span class="hljs-attr">bucket:</span> <span class="hljs-string">actuated-runners</span>
        <span class="hljs-attr">region:</span> <span class="hljs-string">local</span>
        <span class="hljs-attr">use-fallback:</span> <span class="hljs-literal">true</span>
        <span class="hljs-attr">path:</span> <span class="hljs-string">./.git</span>
        <span class="hljs-attr">key:</span> <span class="hljs-string">${{</span> <span class="hljs-string">runner.os</span> <span class="hljs-string">}}-checkout-${{</span> <span class="hljs-string">env.CHECKOUT_DATE</span> <span class="hljs-string">}}</span>
        <span class="hljs-attr">restore-keys:</span> <span class="hljs-string">|
          ${{ runner.os }}-checkout-
</span></code></pre>
<ul>
<li><code>use-fallback</code> - option means that if seaweedfs is not installed on the host, or is inaccessible, the action will fall back to using the GitHub cache.</li>
<li><code>key</code> - as per GitHub's action - created when saving a cache and the key used to search for a cache</li>
<li><code>restore-keys</code> - as per GitHub's action - if no cache hit occurs for key, these restore keys are used sequentially in the order provided to find and restore a cache.</li>
<li><code>bucket</code> - the name of the bucket to use in seaweedfs</li>
<li><code>accessKey</code> and <code>secretKey</code> - the credentials to use to access the bucket - we'd recommend using an organisation-level secret for this</li>
<li><code>endpoint</code> - the IP address <code>192.168.128.1</code> refers to the host machine where the Firecracker VM is running</li>
</ul>
<p>See also: <a href="https://docs.github.com/en/actions/using-workflows/caching-dependencies-to-speed-up-workflows">Official GitHub Actions Cache action</a></p>
<p>You may also want to create a self-signed certificate for the S3 service and then set <code>insecure: false</code> to ensure that the connection is encrypted. If you're running these builds within private repositories, tampering is unlikely.</p>
<p>Roderik explained that the cache key uses a week-year format, rather than a SHA. Why? Because a SHA would change on every build, meaning that a save and load would be performed on every build, using up more space and slowing things down. In this example, There's only ever 52 cache entries per year.</p>
<blockquote>
<p>You define a key which is unique if the cache needs to be updated. Then you define a restore key that matches part or all of the key.
Part means it takes the last one that matches, then updates at the end of the run, in the post part, it then uses the key to upload the zip file if the key is different from the one stored.</p>
</blockquote>
<p>In one instance, a cached checkout went from 2m40s to 11s. That kind of time saving adds up quickly if you have a lot of builds.</p>
<p>Roderik's pipeline has multiple steps, and may need to run multiple times, so we're looking at 55s instead of 13 minutes for 5 jobs or runs.</p>
<p><img src="/images/2023-05-faster-cache/SettleMint.png" alt="Example pipeline"></p>
<blockquote>
<p>One of the team's pipelines</p>
</blockquote>
<p>Here's how to enable a cache for <code>pnpm</code>:</p>
<pre><code class="hljs language-yaml">    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Install</span> <span class="hljs-string">PNPM</span>
      <span class="hljs-attr">uses:</span> <span class="hljs-string">pnpm/action-setup@v2</span>
      <span class="hljs-attr">with:</span>
        <span class="hljs-attr">run_install:</span> <span class="hljs-string">|
          - args: [--global, node-gyp]
</span>
    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Get</span> <span class="hljs-string">pnpm</span> <span class="hljs-string">store</span> <span class="hljs-string">directory</span>
      <span class="hljs-attr">id:</span> <span class="hljs-string">pnpm-cache</span>
      <span class="hljs-attr">shell:</span> <span class="hljs-string">bash</span>
      <span class="hljs-attr">run:</span> <span class="hljs-string">|
        echo "STORE_PATH=$(pnpm store path)" >> $GITHUB_OUTPUT
</span>
    <span class="hljs-bullet">-</span> <span class="hljs-attr">uses:</span> <span class="hljs-string">tespkg/actions-cache@v1</span>
      <span class="hljs-attr">with:</span>
        <span class="hljs-attr">endpoint:</span> <span class="hljs-string">"192.168.128.1"</span>
        <span class="hljs-attr">port:</span> <span class="hljs-number">8333</span>
        <span class="hljs-attr">insecure:</span> <span class="hljs-literal">true</span>
        <span class="hljs-attr">accessKey:</span> <span class="hljs-string">"s3cr3t"</span>
        <span class="hljs-attr">secretKey:</span> <span class="hljs-string">"s3cr3t"</span>
        <span class="hljs-attr">bucket:</span> <span class="hljs-string">actuated-runners</span>
        <span class="hljs-attr">region:</span> <span class="hljs-string">local</span>
        <span class="hljs-attr">use-fallback:</span> <span class="hljs-literal">true</span>
        <span class="hljs-attr">path:</span>
          <span class="hljs-string">${{</span> <span class="hljs-string">steps.pnpm-cache.outputs.STORE_PATH</span> <span class="hljs-string">}}</span>
          <span class="hljs-string">~/.cache</span>
          <span class="hljs-string">.cache</span>
        <span class="hljs-attr">key:</span> <span class="hljs-string">${{</span> <span class="hljs-string">runner.os</span> <span class="hljs-string">}}-pnpm-store-${{</span> <span class="hljs-string">hashFiles('**/pnpm-lock.yaml')</span> <span class="hljs-string">}}</span>
        <span class="hljs-attr">restore-keys:</span> <span class="hljs-string">|
          ${{ runner.os }}-pnpm-store-
</span>
    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Install</span> <span class="hljs-string">dependencies</span>
      <span class="hljs-attr">shell:</span> <span class="hljs-string">bash</span>
      <span class="hljs-attr">run:</span> <span class="hljs-string">|
        pnpm install --frozen-lockfile --prefer-offline
</span>      <span class="hljs-attr">env:</span>
        <span class="hljs-attr">HUSKY:</span> <span class="hljs-string">'0'</span>
        <span class="hljs-attr">NODE_ENV:</span> <span class="hljs-string">development</span>
</code></pre>
<p>Picking a good key and restore key can help optimize when the cache is read from and written to:</p>
<blockquote>
<p>"You need to determine a good key and restore key. For pnpm, we use the hash of the lock file in the key, but leave it out of the restore key. So if I update the lock file, it starts from the last cache, updates it, and stores the new cache with the new hash"</p>
</blockquote>
<p>If you'd like a good starting-point for GitHub Actions Caching, Han Verstraete from our team wrote up a good primer for the actuated docs:</p>
<p><a href="https://docs.actuated.dev/examples/github-actions-cache/">Example: GitHub Actions cache</a></p>
<h2>Conclusion</h2>
<p>We were able to dramatically speed up caching for GitHub Actions by using a self-hosted S3 service. We used Seaweedfs directly on the server running Firecracker with a fallback to GitHub's cache if the S3 service was unavailable.</p>
<p><a href="https://twitter.com/alexellisuk/status/1661282581617229827/"><img src="https://pbs.twimg.com/media/Fw4PQEfWwAIl-6u?format=jpg&#x26;name=medium" alt="Brr"></a></p>
<blockquote>
<p>An <a href="https://amperecomputing.com/en/">Ampere</a> Altra Arm server running parallel VMs using Firecracker. The CPU is going brr. <a href="https://docs.actuated.dev/provision-server/">Find a server with our guide</a></p>
</blockquote>
<p>We also tend to recommend that all customers enable a mirror of the Docker Hub to counter restrictive rate-limits. The other reason is to avoid any penalties that you'd see from downloading large base images - or from downloading small to medium sized images when running in high concurrency.</p>
<p>You can find out how to configure a container mirror for the Docker Hub using actuated here: <a href="https://docs.actuated.dev/tasks/registry-mirror/">Set up a registry mirror</a>. When testing builds for the <a href="https://github.com/discourse/discourse">Discourse</a> team, there was a 2.5GB container image used for UI testing with various browsers preinstalled within it. We found that we could shave off a few minutes off the build time by using the local mirror. Imagine 10x of those builds running at once, needlessly downloading 250GB of data.</p>
<p>What if you're not an actuated customer? Can you still benefit from a faster cache? You could try out a hosted service like AWS S3 or Google Cloud Storage, provisioned in a region closer to your runners. The speed probably won't quite be as good, but it should still be a lot faster than reaching over the Internet to GitHub's cache.</p>
<p>If you'd like to try out actuated for your team, <a href="https://docs.google.com/forms/d/e/1FAIpQLScA12IGyVFrZtSAp2Oj24OdaSMloqARSwoxx3AZbQbs0wpGww/viewform">reach out to us to find out more</a>.</p>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Book 20 mins with me if you think your team could benefit from the below for GitHub Actions:<br><br>ðŸš€ Insights into CI usage across your organisation<br>ðŸš€ Faster x86 builds<br>ðŸš€ Native Arm builds that can actually finish<br>ðŸš€ Fixed-costs &amp; less management<a href="https://t.co/iTiZsH9pgv">https://t.co/iTiZsH9pgv</a></p>&mdash; Alex Ellis (@alexellisuk) <a href="https://twitter.com/alexellisuk/status/1656300308325179393?ref_src=twsrc%5Etfw">May 10, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></div></div></main><footer class="bg-white"><div class="mx-auto max-w-7xl py-12 px-4 sm:px-6 md:flex md:items-center md:justify-between lg:px-8"><div class="flex justify-center space-x-6 md:order-2"><a class="text-gray-400 hover:text-gray-500" href="https://twitter.com/selfactuated"><span class="sr-only">Twitter</span><svg fill="currentColor" viewBox="0 0 24 24" class="h-6 w-6" aria-hidden="true"><path d="M8.29 20.251c7.547 0 11.675-6.253 11.675-11.675 0-.178 0-.355-.012-.53A8.348 8.348 0 0022 5.92a8.19 8.19 0 01-2.357.646 4.118 4.118 0 001.804-2.27 8.224 8.224 0 01-2.605.996 4.107 4.107 0 00-6.993 3.743 11.65 11.65 0 01-8.457-4.287 4.106 4.106 0 001.27 5.477A4.072 4.072 0 012.8 9.713v.052a4.105 4.105 0 003.292 4.022 4.095 4.095 0 01-1.853.07 4.108 4.108 0 003.834 2.85A8.233 8.233 0 012 18.407a11.616 11.616 0 006.29 1.84"></path></svg></a><a class="text-gray-400 hover:text-gray-500" href="https://github.com/self-actuated"><span class="sr-only">GitHub</span><svg fill="currentColor" viewBox="0 0 24 24" class="h-6 w-6" aria-hidden="true"><path fill-rule="evenodd" d="M12 2C6.477 2 2 6.484 2 12.017c0 4.425 2.865 8.18 6.839 9.504.5.092.682-.217.682-.483 0-.237-.008-.868-.013-1.703-2.782.605-3.369-1.343-3.369-1.343-.454-1.158-1.11-1.466-1.11-1.466-.908-.62.069-.608.069-.608 1.003.07 1.531 1.032 1.531 1.032.892 1.53 2.341 1.088 2.91.832.092-.647.35-1.088.636-1.338-2.22-.253-4.555-1.113-4.555-4.951 0-1.093.39-1.988 1.029-2.688-.103-.253-.446-1.272.098-2.65 0 0 .84-.27 2.75 1.026A9.564 9.564 0 0112 6.844c.85.004 1.705.115 2.504.337 1.909-1.296 2.747-1.027 2.747-1.027.546 1.379.202 2.398.1 2.651.64.7 1.028 1.595 1.028 2.688 0 3.848-2.339 4.695-4.566 4.943.359.309.678.92.678 1.855 0 1.338-.012 2.419-.012 2.747 0 .268.18.58.688.482A10.019 10.019 0 0022 12.017C22 6.484 17.522 2 12 2z" clip-rule="evenodd"></path></svg></a><a class="text-gray-400 hover:text-gray-500" href="/rss.xml"><span class="sr-only">RSS</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="h-6 w-6" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" d="M12.75 19.5v-.75a7.5 7.5 0 00-7.5-7.5H4.5m0-6.75h.75c7.87 0 14.25 6.38 14.25 14.25v.75M6 18.75a.75.75 0 11-1.5 0 .75.75 0 011.5 0z"></path></svg></a></div><div class="mt-8 md:order-1 md:mt-0"><p class="text-center text-base text-gray-400">Â© 2022 <a href="https://openfaas.com">OpenFaaS Ltd</a>, Inc. All rights reserved.</p></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"slug":"faster-self-hosted-cache","fileName":"2023-05-24-faster-self-hosted-cache.md","contentHtml":"\u003cp\u003eIn some of our builds for actuated we cache things like the Linux Kernel, so we don't needlessly rebuild it when we update packages in our base images. It can shave minutes off every build meaning our servers can be used more efficiently. Most customers we've seen so far only make light to modest use of GitHub's hosted cache, so haven't noticed much of a latency problem.\u003c/p\u003e\n\u003cp\u003eBut you don't have to spend too long on the \u003ca href=\"https://github.com/actions/cache/issues?q=is%3Aissue+cache+slow+\"\u003eissuer tracker for GitHub Actions\u003c/a\u003e to find people complaining about the cache being slow or locking up completely for self-hosted runners.\u003c/p\u003e\n\u003cp\u003eGo, Rust, Python and other languages don't tend to make heavy use of caches, and Docker has some of its own mechanisms like building cached steps into published images aka \u003cem\u003e\u003ca href=\"https://docs.docker.com/build/cache/backends/inline/\"\u003einline caching\u003c/a\u003e\u003c/em\u003e. But for the Node.js ecosystem, the \u003ccode\u003enode_modules\u003c/code\u003e folder and yarn cache can become huge and take a long time to download. That's one place where you may start to see tension between the speed of self-hosted runners and the latency of the cache. If your repository is a monorepo or has lots of large artifacts, you may get a speed boost by caching that too.\u003c/p\u003e\n\u003cp\u003eSo why is GitHub's cache so fast for hosted runners, and (sometimes) so slow self-hosted runners?\u003c/p\u003e\n\u003cp\u003eSimply put - GitHub runs VMs and the accompanying cache on the same network, so they can talk over a high speed backbone connection. But when you run a self-hosted runner, then any download or upload operations are taking place over the public Internet.\u003c/p\u003e\n\u003cp\u003eSomething else that can slow builds down is having to download large base images from the Docker Hub. We've already \u003ca href=\"https://docs.actuated.dev/tasks/registry-mirror/\"\u003ecovered how to solve that for actuated in the docs\u003c/a\u003e.\u003c/p\u003e\n\u003ch2\u003eSpeeding up in the real world\u003c/h2\u003e\n\u003cp\u003eWe recently worked with Roderik, the CTO of \u003ca href=\"https://settlemint.com\"\u003eSettleMint\u003c/a\u003e to migrate their CI from a self-hosted Kubernetes solution Actions Runtime Controller (ARC) to actuated. He told me that they originally moved from GitHub's hosted runners to ARC to save money, increase speed and to lower the latency of their builds. Unfortunately, running container builds within Kubernetes provided very poor isolation, and side effects were being left over between builds, even with a pool of ephemeral containers. They also wanted to reduce the amount of effort required to maintain a Kubernetes cluster and control-plane for CI.\u003c/p\u003e\n\u003cp\u003eRoderik explained that he'd been able to get times down by using \u003ca href=\"https://pnpm.io\"\u003epnpm\u003c/a\u003e instead of yarn, and said every Node project should try it out to see the speed increases. He believes the main improvement is due to efficient downloading and caching. pnpm is a drop-in replacement for npm and yarn, and is compatible with both.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eIn some cases, we found that downloading dependencies from the Internet was faster than using GitHub's remote cache. The speed for a hosted runner was often over 100MBs/sec, but for a self-hosted runner it was closer to 20MBs/sec.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eThat's when we started to look into how we could run a cache directly on the same network as our self-hosted runners, or even on the machine that was scheduling the Firecracker VMs.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\"With the local cache that Alex helped us set up, the cache is almost instantaneous. It doesn't even have time to show a progress bar.\"\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eLong story short, SettleMint have successfully migrated their CI for x86 and Arm to actuated for the whole developer team:\u003c/p\u003e\n\u003cblockquote class=\"twitter-tweet\"\u003e\u003cp lang=\"en\" dir=\"ltr\"\u003eSuper happy with my new self hosted GHA runners powered by \u003ca href=\"https://twitter.com/selfactuated?ref_src=twsrc%5Etfw\"\u003e@selfactuated\u003c/a\u003e, native speeds on both AMD and ARM bare metal monster machines. Our CI now goes brrrrâ€¦ \u003ca href=\"https://t.co/quZ4qfcLmu\"\u003epic.twitter.com/quZ4qfcLmu\u003c/a\u003e\u003c/p\u003e\u0026mdash; roderik.eth (@r0derik) \u003ca href=\"https://twitter.com/r0derik/status/1661109934346346510?ref_src=twsrc%5Etfw\"\u003eMay 23, 2023\u003c/a\u003e\u003c/blockquote\u003e \u003cscript async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"\u003e\u003c/script\u003e\n\u003cp\u003eThis post is about speed improvements for caching, but if you're finding that QEMU is too slow to build your Arm containers on hosted runners, you may benefit from switching to actuated with bare-metal Arm servers.\u003c/p\u003e\n\u003cp\u003eSee also:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://actuated.dev/blog/how-to-run-multi-arch-builds-natively\"\u003eHow to split up multi-arch Docker builds to run natively\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://actuated.dev/blog/native-arm64-for-github-actions\"\u003eHow to make GitHub Actions 22x faster with bare-metal Arm\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eSet up a self-hosted cache for GitHub Actions\u003c/h2\u003e\n\u003cp\u003eIn order to set up a self-hosted cache for GitHub Actions, we switched out the official \u003ca href=\"https://github.com/actions/cache\"\u003eactions/cache@v3\u003c/a\u003e action for \u003ca href=\"https://github.com/tespkg/actions-cache\"\u003etespkg/actions-cache@v1\u003c/a\u003e created by Target Energy Solutions, a UK-based company, which can target S3 instead of the proprietary GitHub cache.\u003c/p\u003e\n\u003cp\u003eWe then had to chose between Seaweedfs and Minio for the self-hosted S3 server. Of course, there's also nothing stopping you from actually using AWS S3, or Google Cloud Storage, or another hosted service.\u003c/p\u003e\n\u003cp\u003eThen, the question was - should we run the S3 service directly on the server that was running Firecracker VMs, for ultimate near-loopback speed, or on a machine provisioned in the same region, just like GitHub does with Azure?\u003c/p\u003e\n\u003cp\u003eEither would be a fine option. If you decide to host a public S3 cache, make sure that authentication and TLS are both enabled. You may also want to set up an IP whitelist just to deter any bots that may scan for public endpoints.\u003c/p\u003e\n\u003ch3\u003eSet up Seaweedfs\u003c/h3\u003e\n\u003cp\u003eThe \u003ca href=\"https://github.com/seaweedfs/seaweedfs\"\u003eSeaweedfs\u003c/a\u003e README describes the project as:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\"a fast distributed storage system for blobs, objects, files, and data lake, for billions of files! Blob store has O(1) disk seek, cloud tiering. Filer supports Cloud Drive, cross-DC active-active replication, Kubernetes, POSIX FUSE mount, S3 API, S3 Gateway, Hadoop, WebDAV, encryption, Erasure Coding.\"\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eWe liked it so much that we'd already added it to the arkade marketplace, arkade is a faster, developer-focused alternative to brew.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-bash\"\u003earkade get seaweedfs\nsudo \u003cspan class=\"hljs-built_in\"\u003emv\u003c/span\u003e ~/.arkade/bin/seaweedfs /usr/local/bin\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eDefine a secret key and access key to be used from the CI jobs in the \u003ccode\u003e/etc/seaweedfs/s3.conf\u003c/code\u003e file:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e{\n  \"identities\": [\n    {\n      \"name\": \"actuated\",\n      \"credentials\": [\n        {\n          \"accessKey\": \"s3cr3t\",\n          \"secretKey\": \"s3cr3t\"\n        }\n      ],\n      \"actions\": [\n        \"Admin\",\n        \"Read\",\n        \"List\",\n        \"Tagging\",\n        \"Write\"\n      ]\n    }\n  ]\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eCreate \u003ccode\u003eseaweedfs.service\u003c/code\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e[Unit]\nDescription=SeaweedFS\nAfter=network.target\n\n[Service]\nUser=root\nExecStart=/usr/local/bin/seaweedfs server -ip=192.168.128.1 -volume.max=0 -volume.fileSizeLimitMB=2048 -dir=/home/runner-cache -s3 -s3.config=/etc/seaweedfs/s3.conf\nRestart=on-failure\n\n[Install]\nWantedBy=multi-user.target\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWe have set \u003ccode\u003e-volume.max=0 -volume.fileSizeLimitMB=2048\u003c/code\u003e to minimize the amount of space used and to allow large zip files of up to 2GB, but you can change this to suit your needs. See \u003ccode\u003eseaweedfs server --help\u003c/code\u003e for more options.\u003c/p\u003e\n\u003cp\u003eInstall it and check that it started:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003esudo cp ./seaweedfs.service /etc/systemd/system/seaweedfs.service\nsudo systemctl enable seaweedfs\n\nsudo journalctl -u seaweedfs -f\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eTry it out\u003c/h2\u003e\n\u003cp\u003eYou'll need to decide what you want to cache and whether you want to use a hosted, or self-hosted S3 service - either directly on the actuated server or on a separate machine in the same region.\u003c/p\u003e\n\u003cp\u003eRoderik explained that the pnpm cache was important for node_modules, but that actually caching the git checkout saved a lot of time too. So he added both into his builds.\u003c/p\u003e\n\u003cp\u003eHere's an example:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-yaml\"\u003e    \u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003ename:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"Set current date as env variable\"\u003c/span\u003e\n      \u003cspan class=\"hljs-attr\"\u003eshell:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003ebash\u003c/span\u003e\n      \u003cspan class=\"hljs-attr\"\u003erun:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e|\n        echo \"CHECKOUT_DATE=$(date +'%V-%Y')\" \u003e\u003e $GITHUB_ENV\n\u003c/span\u003e      \u003cspan class=\"hljs-attr\"\u003eid:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003edate\u003c/span\u003e\n    \u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003euses:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003etespkg/actions-cache@v1\u003c/span\u003e\n      \u003cspan class=\"hljs-attr\"\u003ewith:\u003c/span\u003e\n        \u003cspan class=\"hljs-attr\"\u003eendpoint:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"192.168.128.1\"\u003c/span\u003e\n        \u003cspan class=\"hljs-attr\"\u003eport:\u003c/span\u003e \u003cspan class=\"hljs-number\"\u003e8333\u003c/span\u003e\n        \u003cspan class=\"hljs-attr\"\u003einsecure:\u003c/span\u003e \u003cspan class=\"hljs-literal\"\u003etrue\u003c/span\u003e\n        \u003cspan class=\"hljs-attr\"\u003eaccessKey:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"s3cr3t\"\u003c/span\u003e\n        \u003cspan class=\"hljs-attr\"\u003esecretKey:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"s3cr3t\"\u003c/span\u003e\n        \u003cspan class=\"hljs-attr\"\u003ebucket:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003eactuated-runners\u003c/span\u003e\n        \u003cspan class=\"hljs-attr\"\u003eregion:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003elocal\u003c/span\u003e\n        \u003cspan class=\"hljs-attr\"\u003euse-fallback:\u003c/span\u003e \u003cspan class=\"hljs-literal\"\u003etrue\u003c/span\u003e\n        \u003cspan class=\"hljs-attr\"\u003epath:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e./.git\u003c/span\u003e\n        \u003cspan class=\"hljs-attr\"\u003ekey:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e${{\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003erunner.os\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e}}-checkout-${{\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003eenv.CHECKOUT_DATE\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e}}\u003c/span\u003e\n        \u003cspan class=\"hljs-attr\"\u003erestore-keys:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e|\n          ${{ runner.os }}-checkout-\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003euse-fallback\u003c/code\u003e - option means that if seaweedfs is not installed on the host, or is inaccessible, the action will fall back to using the GitHub cache.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ekey\u003c/code\u003e - as per GitHub's action - created when saving a cache and the key used to search for a cache\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003erestore-keys\u003c/code\u003e - as per GitHub's action - if no cache hit occurs for key, these restore keys are used sequentially in the order provided to find and restore a cache.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ebucket\u003c/code\u003e - the name of the bucket to use in seaweedfs\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eaccessKey\u003c/code\u003e and \u003ccode\u003esecretKey\u003c/code\u003e - the credentials to use to access the bucket - we'd recommend using an organisation-level secret for this\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eendpoint\u003c/code\u003e - the IP address \u003ccode\u003e192.168.128.1\u003c/code\u003e refers to the host machine where the Firecracker VM is running\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSee also: \u003ca href=\"https://docs.github.com/en/actions/using-workflows/caching-dependencies-to-speed-up-workflows\"\u003eOfficial GitHub Actions Cache action\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eYou may also want to create a self-signed certificate for the S3 service and then set \u003ccode\u003einsecure: false\u003c/code\u003e to ensure that the connection is encrypted. If you're running these builds within private repositories, tampering is unlikely.\u003c/p\u003e\n\u003cp\u003eRoderik explained that the cache key uses a week-year format, rather than a SHA. Why? Because a SHA would change on every build, meaning that a save and load would be performed on every build, using up more space and slowing things down. In this example, There's only ever 52 cache entries per year.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eYou define a key which is unique if the cache needs to be updated. Then you define a restore key that matches part or all of the key.\nPart means it takes the last one that matches, then updates at the end of the run, in the post part, it then uses the key to upload the zip file if the key is different from the one stored.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eIn one instance, a cached checkout went from 2m40s to 11s. That kind of time saving adds up quickly if you have a lot of builds.\u003c/p\u003e\n\u003cp\u003eRoderik's pipeline has multiple steps, and may need to run multiple times, so we're looking at 55s instead of 13 minutes for 5 jobs or runs.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2023-05-faster-cache/SettleMint.png\" alt=\"Example pipeline\"\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eOne of the team's pipelines\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eHere's how to enable a cache for \u003ccode\u003epnpm\u003c/code\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-yaml\"\u003e    \u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003ename:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003eInstall\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003ePNPM\u003c/span\u003e\n      \u003cspan class=\"hljs-attr\"\u003euses:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003epnpm/action-setup@v2\u003c/span\u003e\n      \u003cspan class=\"hljs-attr\"\u003ewith:\u003c/span\u003e\n        \u003cspan class=\"hljs-attr\"\u003erun_install:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e|\n          - args: [--global, node-gyp]\n\u003c/span\u003e\n    \u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003ename:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003eGet\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003epnpm\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003estore\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003edirectory\u003c/span\u003e\n      \u003cspan class=\"hljs-attr\"\u003eid:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003epnpm-cache\u003c/span\u003e\n      \u003cspan class=\"hljs-attr\"\u003eshell:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003ebash\u003c/span\u003e\n      \u003cspan class=\"hljs-attr\"\u003erun:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e|\n        echo \"STORE_PATH=$(pnpm store path)\" \u003e\u003e $GITHUB_OUTPUT\n\u003c/span\u003e\n    \u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003euses:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003etespkg/actions-cache@v1\u003c/span\u003e\n      \u003cspan class=\"hljs-attr\"\u003ewith:\u003c/span\u003e\n        \u003cspan class=\"hljs-attr\"\u003eendpoint:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"192.168.128.1\"\u003c/span\u003e\n        \u003cspan class=\"hljs-attr\"\u003eport:\u003c/span\u003e \u003cspan class=\"hljs-number\"\u003e8333\u003c/span\u003e\n        \u003cspan class=\"hljs-attr\"\u003einsecure:\u003c/span\u003e \u003cspan class=\"hljs-literal\"\u003etrue\u003c/span\u003e\n        \u003cspan class=\"hljs-attr\"\u003eaccessKey:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"s3cr3t\"\u003c/span\u003e\n        \u003cspan class=\"hljs-attr\"\u003esecretKey:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"s3cr3t\"\u003c/span\u003e\n        \u003cspan class=\"hljs-attr\"\u003ebucket:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003eactuated-runners\u003c/span\u003e\n        \u003cspan class=\"hljs-attr\"\u003eregion:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003elocal\u003c/span\u003e\n        \u003cspan class=\"hljs-attr\"\u003euse-fallback:\u003c/span\u003e \u003cspan class=\"hljs-literal\"\u003etrue\u003c/span\u003e\n        \u003cspan class=\"hljs-attr\"\u003epath:\u003c/span\u003e\n          \u003cspan class=\"hljs-string\"\u003e${{\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003esteps.pnpm-cache.outputs.STORE_PATH\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e}}\u003c/span\u003e\n          \u003cspan class=\"hljs-string\"\u003e~/.cache\u003c/span\u003e\n          \u003cspan class=\"hljs-string\"\u003e.cache\u003c/span\u003e\n        \u003cspan class=\"hljs-attr\"\u003ekey:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e${{\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003erunner.os\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e}}-pnpm-store-${{\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003ehashFiles('**/pnpm-lock.yaml')\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e}}\u003c/span\u003e\n        \u003cspan class=\"hljs-attr\"\u003erestore-keys:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e|\n          ${{ runner.os }}-pnpm-store-\n\u003c/span\u003e\n    \u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003ename:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003eInstall\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003edependencies\u003c/span\u003e\n      \u003cspan class=\"hljs-attr\"\u003eshell:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003ebash\u003c/span\u003e\n      \u003cspan class=\"hljs-attr\"\u003erun:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e|\n        pnpm install --frozen-lockfile --prefer-offline\n\u003c/span\u003e      \u003cspan class=\"hljs-attr\"\u003eenv:\u003c/span\u003e\n        \u003cspan class=\"hljs-attr\"\u003eHUSKY:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e'0'\u003c/span\u003e\n        \u003cspan class=\"hljs-attr\"\u003eNODE_ENV:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003edevelopment\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ePicking a good key and restore key can help optimize when the cache is read from and written to:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\"You need to determine a good key and restore key. For pnpm, we use the hash of the lock file in the key, but leave it out of the restore key. So if I update the lock file, it starts from the last cache, updates it, and stores the new cache with the new hash\"\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eIf you'd like a good starting-point for GitHub Actions Caching, Han Verstraete from our team wrote up a good primer for the actuated docs:\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://docs.actuated.dev/examples/github-actions-cache/\"\u003eExample: GitHub Actions cache\u003c/a\u003e\u003c/p\u003e\n\u003ch2\u003eConclusion\u003c/h2\u003e\n\u003cp\u003eWe were able to dramatically speed up caching for GitHub Actions by using a self-hosted S3 service. We used Seaweedfs directly on the server running Firecracker with a fallback to GitHub's cache if the S3 service was unavailable.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://twitter.com/alexellisuk/status/1661282581617229827/\"\u003e\u003cimg src=\"https://pbs.twimg.com/media/Fw4PQEfWwAIl-6u?format=jpg\u0026#x26;name=medium\" alt=\"Brr\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eAn \u003ca href=\"https://amperecomputing.com/en/\"\u003eAmpere\u003c/a\u003e Altra Arm server running parallel VMs using Firecracker. The CPU is going brr. \u003ca href=\"https://docs.actuated.dev/provision-server/\"\u003eFind a server with our guide\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eWe also tend to recommend that all customers enable a mirror of the Docker Hub to counter restrictive rate-limits. The other reason is to avoid any penalties that you'd see from downloading large base images - or from downloading small to medium sized images when running in high concurrency.\u003c/p\u003e\n\u003cp\u003eYou can find out how to configure a container mirror for the Docker Hub using actuated here: \u003ca href=\"https://docs.actuated.dev/tasks/registry-mirror/\"\u003eSet up a registry mirror\u003c/a\u003e. When testing builds for the \u003ca href=\"https://github.com/discourse/discourse\"\u003eDiscourse\u003c/a\u003e team, there was a 2.5GB container image used for UI testing with various browsers preinstalled within it. We found that we could shave off a few minutes off the build time by using the local mirror. Imagine 10x of those builds running at once, needlessly downloading 250GB of data.\u003c/p\u003e\n\u003cp\u003eWhat if you're not an actuated customer? Can you still benefit from a faster cache? You could try out a hosted service like AWS S3 or Google Cloud Storage, provisioned in a region closer to your runners. The speed probably won't quite be as good, but it should still be a lot faster than reaching over the Internet to GitHub's cache.\u003c/p\u003e\n\u003cp\u003eIf you'd like to try out actuated for your team, \u003ca href=\"https://docs.google.com/forms/d/e/1FAIpQLScA12IGyVFrZtSAp2Oj24OdaSMloqARSwoxx3AZbQbs0wpGww/viewform\"\u003ereach out to us to find out more\u003c/a\u003e.\u003c/p\u003e\n\u003cblockquote class=\"twitter-tweet\"\u003e\u003cp lang=\"en\" dir=\"ltr\"\u003eBook 20 mins with me if you think your team could benefit from the below for GitHub Actions:\u003cbr\u003e\u003cbr\u003eðŸš€ Insights into CI usage across your organisation\u003cbr\u003eðŸš€ Faster x86 builds\u003cbr\u003eðŸš€ Native Arm builds that can actually finish\u003cbr\u003eðŸš€ Fixed-costs \u0026amp; less management\u003ca href=\"https://t.co/iTiZsH9pgv\"\u003ehttps://t.co/iTiZsH9pgv\u003c/a\u003e\u003c/p\u003e\u0026mdash; Alex Ellis (@alexellisuk) \u003ca href=\"https://twitter.com/alexellisuk/status/1656300308325179393?ref_src=twsrc%5Etfw\"\u003eMay 10, 2023\u003c/a\u003e\u003c/blockquote\u003e \u003cscript async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"\u003e\u003c/script\u003e","title":"Fixing the cache latency for self-hosted GitHub Actions","description":"The cache for GitHub Actions can speed up CI/CD pipelines. But what about when it slows you down?","tags":["cicd","githubactions","cache","latency","yarn"],"author_img":"alex","image":"/images/2023-05-faster-cache/background.png","date":"2023-05-24"}},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"faster-self-hosted-cache"},"buildId":"n3VvHl02riewG3IqG5uON","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>